



# 一、概念描述

## 宏观概念

### 统计学（一元与多元）

一元统计分析可以认为是研究一个随机变量的统计规律的学科，多元统计分析则是在研究多个随机变量之间相互依赖关系。大体上讲，是收集数据，提取数据中的信息，对所研究的问题作出推断。

Kendall在《多元统计》一书中，把多元统计研究的内容归为以下几类：降维问题、分类问题、变量间相互依赖关系、多元分布统计推断（参数估计与假设检验）、分布的理论基础。

又可分为参数统计与非参数统计。参数统计依赖“模型”，先假定数据服从某个模型，然后估计这个模型中的参数，或者对模型的有效性作出检验，因此统计学可以成为“建模”的手段。非参数统计不对数据满足的模型做出假设，只考虑对数据做出某些推断。

### 数据科学

研究数据的科学。研究手段既涵盖了统计的方法（推断、检验），又涵盖了机器的方法（设计算法），当然还有一些别的（比如具体领域内的专业知识）。可以看作是统计与机器学习的应用。

### 人工智能

人工智能 (Artificial Intelligence, AI) 可以被定义成一个像人类一样理性思考与行动的系统。不过，现在的人工智能范围极其广阔，能够完成特定的任务的机器系统，似乎都可以被冠以人工智能的名字。机器学习是人工智能领域的一部分。人工智能可以用来做数据分析（拥计算机做啥都叫个人工智能……这个词都被用烂了）。

### 机器学习

机器学习本质上是在构筑一个固定的“算法”，这个算法可以针对一些数据算出一些结论。具体来说，机器学习所做的事情是让机器从数据中确定一些参数，进而确定算法，进而处理新的数据。这样的算法可以来自一个统计学中的模型，也可以来自纯粹穷举，或者是什么其他思路。至于机器学习与统计的关系，应该说有所交集，但不相同。

从不同的角度看，机器学习方法有多种分类。可以分为参数方法和非参数方法；有监督方法和无监督方法；传统机器学习与深度学习，等等。

## 数据描述

为了叙述上的统一，在此规定一些概念。

假设我们有这样的表格：

| 编号  | 属性x1   | 属性x2   | ...  | 属性xp   | 目标y |
| ----- | -------- | -------- | ---- | -------- | ----- |
| 个体1 | $x_{11}$ | $x_{12}$ | ...  | $x_{1p}$ | $y_1$ |
| 个体2 | $x_{21}$ | $x_{22}$ | ...  | $x_{2p}$ | $y_2$ |
| ...   | ...      | ...      | ...  | ...      | ...   |
| 个体n | $x_{n1}$ | $x_{n2}$ | ...  | $x_{np}$ | $y_n$ |

以及这样的关系：

$$
y=f(\beta,\theta,x_1,x_2,...,x_p)
$$

可以叙述以下概念：

数据集：记录数据的表格。通常每行记录一个个体的信息，每列记录不同个体的同属性数据。不包含目标列的数据可以用矩阵$X=(x_{ij})$记。

样本：数据集的一行是一个样本。

特征：数据集的每一列是一个特征。通常将其中一项认为是受其他特征影响的因变量，其他的是自变量。有时，仅仅把自变量列看作特征。

标签：作为预测目标的特征是标签，或者叫目标数组、因变量，可以用$y=(y_1,\cdots,y_n)'$记。

模型：自变量与因变量的关系即模型，模型本质上是函数，但未必有表达式。在上例中是$f$。

超参数：在选择模型类时就要确定的参数，比如是否中心化等。在上例中是$\theta$。这些参数由于各种原因，不适合根据数据来确定，需要人为指定。

参数：模型中待定的变量，需要根据数据求出一些值作为参数，使得模型的预测效果最好。在上例中是$\beta$。在确定$\beta$之前，模型其实是模型空间中的众多函数，确定了$\beta$之后，模型才是一个确定可用的函数。二者容易混淆，要根据语境判断。



# 二、分析过程

数据分析的大致过程是数据预处理→选择模型→训练模型→评价模型，如果模型比较好就可以使用，否则重新选择模型。有时我们对数据服从的模型没有头绪，可以先进行数据感知，查看数据的分布特点，再做进一步打算。

数据预处理，指的是讲原始数据处理成便于后续操作的过程。其中有的是为了让后续操作具有可能性，比如缺失值处理、特征降维、离散特征连续化等；有的则是为了让模型具有更好的效果，比如去噪、归一化等。

数据感知，即用各种指标反应数据的特点。通常包括画散点图查看样本分布、计算协方差矩阵、计算特征与标签的相关来反应特征重要程度等等。

选择模型顾名思义，就是选择合适的模型类型，并确定超参数。

训练模型，指的是根据已知的数据，求出模型的参数使得模型达到最有效果。

评价模型，也可称为模型诊断，指将一些数据带入求解出的模型算出一些指标，用指标衡量这个模型的好坏。这一步通常和训练模型结合进行，先将数据划分为训练集与测试集两部分，用训练集的数据求解参数，再用测试集的数据带入模型计算评价指标。还有交叉验证等更加复杂的方案。

在训练神经网络时，情况要复杂一些。由于训练神经网络需要的数据量非常大，通常要将全部数据分为很多小部分，每一部分称为一个batch，每次只向神经网络中输入一个batch，这才能够运行。如果全部的数据还不够多，就将这些数据重复使用，每一次使用全部数据称为一个epoch。实际上模型运行的次数是epoch_n * batch_n 这么多次，每次计算了batch_size条样本。



# 三、学习的延伸

## 元学习

如果有一个“模型产生器”$F$，它能根据一个已知的数据集$D$、和对应的任务目标$T$（比如辨别猫和狗），返回一个可以完成任务的模型$f$，$f$可以应用到数据集$D$或者新的未知数据上，进行$ \hat y=f(x)$的预测——即使数据集$D$是样本量小且目标新奇的也依然有效——那就解决了上述的问题。只要有确定的$D,T$，那么$f=F(D,T)$就是我们想要得到的模型。

这个“模型产生器”$F$，实际上也是一个“模型”。传统的机器学习所给出的模型$f$，描述的是特征$x$与标签$y$之间的函数关系，训练模型的目的是确定其参数$\theta$；而“模型产生器”$F$，描述的是任务$ D,T$与解决方案$f$之间的关系，它也有需要被训练确定的参数$\omega$。$F$是制造模型的模型，可以命名为meta-模型，也即元模型。$F$的参数$\omega$就是我们想求出的“先验知识”，确定了参数$\omega$，$F$才能根据新的任务$D,T$给出可靠的模型$f$。

传统的机器学习，学习的内容是特征$x$与标签$y$之间的函数关系；而产生$F$的过程，学习的内容是任务$ D,T$与解决方案$f$之间的函数关系，也即是在学习如何”学习得到$f$“。所以这一过程是”学习的学习“，可以命名为meta-学习，也即元学习。

总的来说，元学习的目标是得到一个模型$F$（或者说是参数$\omega$），$F$会针对特定的任务$T$，在给定的数据集$D$上训练得出一个描述数据的模型$f$。而且，即使样本少（few-shot）、任务类型多（multi-task），计算速度和准确度也依然较高。



## 持续学习

考虑这样两种需求：1、模型建立之后，还会不断产生新的数据，用更多数据训练，理应产生更好的模型，那么如何利用新的数据修改已经建立好的模型呢？2、模型建立之后，出于一些原因丢失了历史数据，此时如果根据新数据重新训练就会丢失之前的信息，如何处理？

以上两个问题以指向了同一个解决方案——找到合适的建模方法，能让模型在保有以往学习到的知识的前提下，输入新数据，学习到新知识。这就是持续学习希望做到的事情。

用数学的语言来描述则是，对于一系列的任务,${(X^1,Y^1 ),…,(X^T,Y^T )}$，每一个任务$t$包括$n_t$组数据$X^t =\{x^{t,i}\}_{i=1}^{n_t},Y^t=\{y^{t,i}\}_{i=1}^{n_t}$，假设神经网络等机器学习的模型为$f(x,θ)$，其中$θ$为模型参数，持续学习要解决的问题为：对于新的任务$T^*$，从参数$θ^{T}$出发，仅利用新观测到的数据$(X^{T^*},Y^{T^*}) $，期望学习到参数$θ^{T^*}$，使其(a)保持甚至提高以往学到的知识 (b)解决新任务$T$。