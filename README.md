[toc]

# 说明

1. 笔记为个人学习记录，内容来自网页、书籍、文档等。记录了各种数据科学相关的概念与模型、算法，包括它们的假设、核心思路、性质、计算方法、应用场景等。由于并非一次写成，在框架结构上可能存在诸多问题，我会在记录的过程中不断调整。

1. 以下笔记不涉及学科讲解。默认读者拥有线性代数、概率论、数理统计的基本知识。

1. 代码部分，用到的库包括但不限于numpy，pandas，sklearn等。默认读者拥有Python的基本知识，以及了解这些库。

1. 文中的一些概念，会有多种称呼或者记法。这部分是因为不同的参考文献中，记法各不相同；部分是因为我为了便于理解、区分概念，擅作主张的起了、或者修改了一些名字与记法。




# 新目录

## 0、需要声明的东西

- [x] 通用概念阐释

## 1、数学内容

- [ ] 奇异值分解（旧文件未迁移）
- [ ] 傅里叶变换（旧文件未迁移）
- [ ] 小波分析
- [ ] 凸优化
- [x] 时间序列分析基础（只有标题，没写内容）
- [x] 经验模态分解EMD及其衍生
- [x] 常用损失函数


## 2、数据处理通用方法

- [ ] 数据预处理 - 样本均衡处理：欠采样、过采样、用模型均衡（旧文件未迁移）
- [ ] 可视化图表
- [ ] 特征提取
- [x] 相关性分析

  相关性系数

  典型相关分析

  动态时间规整

## 3、机器学习通用方法

- [x] 模型集成与提升
- [x] 模型选择与评估

## 4、统计与传统机器学习

- [ ] 线性回归与其衍生（旧文件未迁移）
- [ ] Logstic回归
- [x] 贝叶斯相关方法
- [x] 支持向量机
- [x] 决策树与随机森林
- [ ] 最近邻法（旧文件未迁移）
- [x] 主成分分析PCA
- [x] 因子分析

## 5、深度学习的基本单元

- [x] 神经网络的基本概念
- [ ] 多层感知机（旧文件未迁移）
- [x] 常用激活函数
- [ ] 优化器
- [x] 卷积神经网络CNN
- [x] 循环神经网络RNN及其变种
- [x] 自编码器AE及其扩展
- [x] 神经网络训练的技巧（待完善）
	残差连接
	BN/LN
	warm up
	dropout

## 6、针对各种目标的复杂网络

### CV

- [x] R-CNN系网络
- [x] ViT图像分类

### NLP

- [x] Attention&Transformer
- [x] BERT
- [x] ChatGPT

### 生成式模型

- [x] 生成对抗网络GANs
- [x] 去噪概率扩散模型DDPM

## 7、广泛的学习

- [ ] 迁移学习
- [ ] 元学习（旧文件未迁移）
- [ ] 持续学习（旧文件未迁移）
- [ ] 强化学习（只有简介）
- [ ] 增量学习iCaRL（只记录了参考来源）



# 更新说明

2022/9/14：完成搬运。在此之前的笔记都未记录参考资料，图片也均未注明来源。之后的会注意加上。

2022/11/17：决定对目录再次进行调整。调整之后，每篇笔记不再编号，根据目录里的组织方式阅读。之后会缓慢将笔记按照此新目录整理。（咕咕咕）

2024/3/28：列出了代完善目录清单



# 旧目录

一、数据分析的基本概念

二、数据感知与预处理方法

三、模型参数选择与评价

四、有监督学习-分类问题

五、有监督学习-回归问题

六、无监督学习-聚类问题

七、无监督学习-降维问题

八、深度学习与神经网络方法

九、假设检验方法

十、时间序列模型

十一、一些数学理论

十二、更多学习理论