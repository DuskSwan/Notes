# 单变量位置推断

### Wilcoxon符号秩检验

用于研究对称分布的样本，其对称中心的位置。换成数学语言，假设$X_1,X_2,...,X_n$来自某个对称的总体$F(x)$，且$F(x)$关于$x=\theta$对称，我们想要检验是否成立原假设$H_0:\theta=0$。

在R语言中，使用`wilcox.test(x)`来进行检验。

# 关联性分析

### Ridit得分

也称参照单位分析法。

考虑如下的$r\times s$列联表

|          | B1       | B2       | ...  | Bs       | 总计     |
| -------- | -------- | -------- | ---- | -------- | -------- |
| A1       | O11      | O12      | ...  | O1s      | O1·      |
| $\vdots$ | $\vdots$ | $\vdots$ |      | $\vdots$ | $\vdots$ |
| Ar       | Or1      | Or2      | ...  | Ors      | Or·      |
| 总计     | O·1      | O·2      | ...  | O·s      | O··      |

每一行代表一个组（或一种处理，一个项目，一种问题），称处理类；每一列代表该组上的数值的“剧烈程度”，称顺序类，一般假定$B_1<B_2<\cdots<B_s$；$O_{ij}$就代表处理$A_i$在程度$B_j$上的相应数目。

我们想要研究这样的问题：不同的处理$A_1,...,A_r$之间，是否有强弱程度的差异，也即是否有一些$A_i$的响应倾向于更大或更小的$B_j$。（比如头疼与腿疼，在感知上头疼更剧烈，人们在调查时就会倾向给头疼打高分。）所以提出假设
$$
\begin{align}
H_0:& A_1,A_2,\cdots,A_r \text{之间没有强弱顺序} \\
H_1:& \text{至少存在一对}i,j,\text{使得}A_i \neq A_j
\end{align}
$$
我们的思路是，先给每个处理$A_i$计算一个“得分”$R_i$来代表其强弱程度，再依赖$R_i$来构造统计量进行检验。

假设$p_{i\cdot }$是处理类$ A_i$的边缘概率，$p_{\cdot j}$是顺序类$ B_i$的边缘概率，记$F_j^B=\sum\limits_{k=1}^jp_{\cdot k}$是前$j$个顺序类的累计概率，那么Ridit得分定义为
$$
\begin{align}
R_1 &= \frac12 p_{\cdot 1} \\
R_2 &= F_1^B+\frac12 p_{\cdot 2} \\
 & \cdots \\
R_j &= F_{j-1}^B+\frac12 p_{\cdot j} \\
 &=\frac{F_{j-1}^B + F_{j}^B}{2},\quad j=2,3,...,s
\end{align}
$$


在实践中，用频率$ \displaystyle\frac{O_{\cdot j}}{O_{\cdot\cdot}}$来作为概率$p_{\cdot j}$的估计。

### 对数线性模型

原假设为$H_0: \text{行列无关}$。

用对数线性模型检验关联性，思路如下：先根据$r\times s$列联表中的值，得到一个模型，该模型以行列为自变量，以表中的值为目标变量。（在原假设，即行列不相关的条件下）求解模型后，将模型的拟合值看作表中单元格的期望取值，再用拟合优度检验等方法检验实际值与期望值的接近程度，如果不接近，则拒绝原假设，承认相关性。

考虑如下的$r\times s$列联表数据

|          | $B_1$    | $B_2$    | ...  | $B_s$    | 总计       |
| -------- | -------- | -------- | ---- | -------- | ---------- |
| $A_1$    | $n_{11}$ | $n_{12}$ | ...  | $n_{1s}$ | $n_{1·}$   |
| $\vdots$ | $\vdots$ | $\vdots$ |      | $\vdots$ | $\vdots$   |
| $A_r$    | $n_{r1}$ | $n_{r2}$ | ...  | $n_{rs}$ | $n_{r·}$   |
| 总计     | $n_{·1}$ | $n_{·2}$ | ...  | $n_{·s}$ | $n=n_{··}$ |

其中$n_{ij}$可以看做样本取值$(A_i,B_j)$的频数，而$n_{ij}/n$则是频率。设$p_{i\cdot }$是取到$ A_i$的边缘概率，$p_{\cdot j}$是取到$ B_i$的边缘概率，$p_{ij}$是取到$(A_i,B_j)$的概率。显然频率$f_{ij}=n_{ij}/n$是频率$p_{ij}$的估计。

首先做一些恒等变换：
$$
\begin{align}
p_{ij} &= \frac1{rs} \times rp_{i\cdot} \times sp_{\cdot j} \times \frac{p_{ij}}{p_{i\cdot}p_{\cdot j}} \\
\ln(p_{ij}) &= \ln(\frac1{rs}) + \ln(rp_{i\cdot})+ \ln(sp_{\cdot j} ) +\ln(\frac{p_{ij}}{p_{i\cdot}p_{\cdot j}}) \\
&= \ln(rs) 
+\left[\ln(p_{i\cdot})-\ln(rs)\right] 
+\left[\ln(p_{\cdot j})-\ln(rs)\right] 
+\left[\ln(p_{ij})-\ln(p_{i\cdot})-\ln(p_{\cdot j})+\ln(rs)\right] \\
&= \mu+\mu_{A(i)}+\mu_{B(j)}+\mu_{AB(ij)}
\end{align}
$$
接下来，只要在原假设下给出$\mu, \mu_{A(i)}, \mu_{B(j)}, \mu_{AB(ij)}$的估计，就可以得出$\ln(p_{ij})$的“期望值”。通过比较期望值与实际值，来衡量是否存在独立性。（值得注意的是，尽管可以从样本中直接算出 $\ln(rs),\ln(p_{i\cdot}),\ln(p_{\cdot j}),\ln(p_{ij})$的值，但那并不依赖原假设。我们的目的是估计出$\mu, \mu_{A(i)}, \mu_{B(j)}, \mu_{AB(ij)}$在原假设下的结果，这样和真实数据比较才有意义。）

这四者的估计量如下：
$$
\begin{align}
\hat\mu & = \frac{1}{rs}\sum\sum \ln(p_{ij}) \\
\hat\mu_{A(i)} & = \frac{1}{s}\sum_{j=1}^s \ln(p_{ij})-\mu \\
\hat\mu_{B(j)} & = \frac{1}{r}\sum_{i=1}^r \ln(p_{ij})-\mu \\
\hat\mu_{AB(ij)} & = \ln(p_{ij})-\mu-\mu_{A(i)}-\mu_{B(j)} \\
\end{align}
$$

其中的概率$p_{ij}$用频率$f_{ij}=n_{ij}/n$代替，就能从$\ln(f_{ij})$得到$\hat\mu,\hat\mu_{A(i)},\hat\mu_{B(j)},\hat\mu_{AB(ij)}$，进而加和得到全部的$\ln(p_{ij})$的估计值，不妨记为$\widehat{\ln(p_{ij})}$，进而又可以得到单元格的期望频数$m_{ij}=e^{\widehat{\ln(p_{ij})}}$。

检验$m_{ij}$与$n_{ij}$的接近程度，越接近则说明原本的行列越无关。这个检验可以是Pearson $\chi^2$检验或者对数似然比检验。



### 对应分析

其目的也是判断列联表的行列之间是否有关联性。先叙述一些定义

考虑如下的$p\times q$列联表数据

|          | 1        | 2        | $\cdots$ | $q$      | 总计       |
| -------- | -------- | -------- | -------- | -------- | ---------- |
| 1        | $n_{11}$ | $n_{12}$ | $\cdots$ | $n_{1s}$ | $n_{1·}$   |
| $\vdots$ | $\vdots$ | $\vdots$ |          | $\vdots$ | $\vdots$   |
| $p$      | $n_{r1}$ | $n_{r2}$ | $\cdots$ | $n_{rs}$ | $n_{r·}$   |
| 总计     | $n_{·1}$ | $n_{·2}$ | $\cdots$ | $n_{·s}$ | $n=n_{··}$ |

记其频率矩阵为$P=(p_{ij})=(n_{ij}/n)$，频率矩阵的行和记为$r=(p_{1\cdot},\cdots,p_{p\cdot})'=(n_{1\cdot}/n,\cdots,n_{p\cdot}/n)'$，列和记为$c'=(p_{\cdot1},\cdots,p_{\cdot q})=(n_{\cdot1}/n,\cdots,n_{\cdot q}/n)$，它们分别称为行密度与列密度，其元素称为行边缘密度与列边缘密度。

### 典型相关分析

两个变量之间的相关性，可以用相关性系数来衡量；一个变量与一个向量之间的相关性，可以用复相关系数来衡量。那么两个向量之间的相关关系如何衡量？例如，语文成绩由阅读速度、理解才能决定，数学成绩由运算速度、运算准确度决定，那么语文能力（阅读速度，理解才能）与数学能力（运算速度，运算准确度）在多大程度上相关？这就是典型相关分析（canonical correlation analysis, CCA）要解决的问题。

#### 思路

假设要研究的是向量$x=(x_1,x_2,\cdots,x_p)$和$y=(y_1,y_2,\cdots,y_q)$。考虑这样的方法：对向量$x$与$y$施以线性函数$u=a'x,v=b'y$，再计算$u$与$v$的相关系数，通过选择合适的$a,b$来使$\rho(u,v)$最大。

由于
$$
\operatorname{cov}(u,v)
=\operatorname{cov}(a'x,b'y)
=a' \operatorname{cov}(x,y) b
=a'\Sigma_{12} b \\ 
V(u)=V(a'x)=a'V(x)a=a'\Sigma_{11}a \\
V(v)=V(b'y)=b'V(y)b=b'\Sigma_{22}b
$$
其中的$\Sigma_{12},\Sigma_{11},\Sigma_{22}$来自$V\begin{pmatrix}x\\y\end{pmatrix}=\begin{pmatrix}\Sigma_{11}&\Sigma_{12}\\\Sigma_{21}&\Sigma_{22}\end{pmatrix}$，所以有
$$
\rho(u,v)=\frac{a'\Sigma_{12}b}{\sqrt{a'\Sigma_{11}a}\sqrt{b'\Sigma_{22}b}}
$$
由于线性倍增不改变相关系数，我们常常限定$V(u)=V(v)=1$，也即添加了约束$a'\Sigma_{11}a=b'\Sigma_{22}b=1$。在此基础上求$a,b$使得$\rho(u,v)=a'\Sigma_{12}b$最大。

记
$$
\begin{align}
C&=\Sigma_{11}^{-1} \Sigma_{12} \Sigma_{22}^{-1} \Sigma_{21} \\
D&=\Sigma_{22}^{-1} \Sigma_{21} \Sigma_{11}^{-1} \Sigma_{12} \\
E&=\Sigma_{11}^{-\frac12}\Sigma_{12}\Sigma_{22}^{-1}\Sigma_{21}\Sigma_{11}^{-\frac12} \\
F&=\Sigma_{22}^{-\frac12}\Sigma_{21}\Sigma_{11}^{-1}\Sigma_{12}\Sigma_{22}^{-\frac12}
\end{align}
$$
显然四个矩阵都是半正定的（因为可分解为对称阵的乘积）。又由于定理“对$p\times q$阶和$q\times p$阶矩阵$P,Q$，$PQ$与$QP$的非零特征值相同”，所以$C,D,E,F$有着相同的$m$个非零特征值，且$m=\rank \Sigma_{12}$，记之为$\lambda_1\geqslant\lambda_2\geqslant\cdots\geqslant\lambda_m>0$。矩阵$C,D,E,F$的属于这些特征值的正交单位特征向量分别记为$a_i,b_i,\alpha_i,\beta_i(i=1,2,...,m)$。

现在，只要取$a=a_1,b=b_1$，就是上述的使得$\rho(u,v)$最大的解。将$a_1,b_1$称为第一对典型系数向量；$u_1=a_1'x,v_1=b_1'y$称为第一对典型变量，它们提取了$x$与$y$之间相关的最主要部分；$\rho_1=\sqrt{\lambda_1}=\rho(u_1,v_1)$称为第一典型相关系数。

在排除第一对典型变量提取的相关信息之后，还可以以相同的思路（使得$\rho(u_i,v_i)=a_i'\Sigma_{12}b_i$最大）继续计算第二对典型变量，仍然要求$V(u_i)=V(v_i)=1$，且要保证每一对典型变量与之前的典型变量包含的信息不重复，也即$\rho(u_i,v_j)=0,i\neq j$。可以证明，满足这样条件的第$i$典型系数向量恰是$a_i,b_i$，第$i$典型相关系数恰是$\rho_i=\sqrt{\lambda_i}$。

记$u=(u_1,...,u_m)',v=(v_1,...,v_m)'$,$A=(a_1,...,a_m),B=(b_1,...,b_m)$，那么可以写成矩阵性质$u=A'x,v=B'y$。

在实践中，只要用样本的协方差矩阵来代替总体的协方差矩阵即可。设数据矩阵为
$$
(X \ Y)=\begin{pmatrix}
x_1' & y_1' \\
\vdots & \vdots \\
x_n' & y_n' \\
\end{pmatrix}=\begin{pmatrix}
x_{11} & \cdots & x_{1p} & y_{11} & \cdots & y_{1q} \\
\vdots &   & \vdots & \vdots &   & \vdots \\
x_{n1} & \cdots & x_{np} & y_{n1} & \cdots & y_{nq} \\
\end{pmatrix}
$$
则样本协方差矩阵为
$$
S=\begin{pmatrix}
S_{11} & S_{12} \\
S_{21} & S_{22} \\
\end{pmatrix}=\frac{1}{n-1}
\begin{pmatrix}
\sum\limits_{i=1}^n(x_i-\bar x)(x_i-\bar x)' & \sum\limits_{i=1}^n(x_i-\bar x)(y_i-\bar y)' \\
\sum\limits_{i=1}^n(y_i-\bar y)(x_i-\bar x)' & \sum\limits_{i=1}^n(y_i-\bar y)(y_i-\bar y)' \\
\end{pmatrix}
$$
用$S$代替$\Sigma$算得$\rho_i,a_i,b_i$的估计量，记为$r_i,\hat a_i,\hat b_i$。实际应用中，会使用中心化后的典型变量（原理参考性质-标准化改进）$ u_i=\hat a_i(x-\bar x),v_i=\hat b_i(y-\bar y)$，又由于有$n$组$(x_j,y_j)$，所以可以算出$n$组典型变量，记之为
$$
 u_{ji}=\hat a_i(x_j-\bar x),\ v_{ji}=\hat b_i(y_j-\bar y),\ j=1,2,...,n,\ i=1,2,...,m
$$
其中$m$如前所述，是典型变量的数量，也即$S_{12}$（作为$\Sigma_{12}$的估计）的秩。

#### 性质

1. （典型变量之间的相关性）对于众多典型变量$u_1,...u_m,v_1,...,v_m$，仅有同对的$u_i,v_i$相关，其余均不相关，也即$ \rho(u_i,u_j)=\rho(v_i,v_j)=\rho(u_i,v_j)=0$对一切$i\neq j$成立。

1. （原始变量与典型变量的相关性）沿用记法$u=(u_1,...,u_m)',v=(v_1,...,v_m)'$,$A=(a_1,...,a_m),B=(b_1,...,b_m)$，那么可以算得
   $$
   \begin{align}
   \text{Cov}(x,u)&=\text{Cov}(x,A'x)=\Sigma_{11}A \\
   \text{Cov}(x,v)&=\text{Cov}(x,B'y)=\Sigma_{12}B \\
   \text{Cov}(y,u)&=\text{Cov}(y,A'x)=\Sigma_{21}A \\
   \text{Cov}(y,v)&=\text{Cov}(y,B'y)=\Sigma_{22}B \\
   \end{align}
   $$
   进而得到
   $$
   \begin{align}
   \rho(x,u)&=D_1^{-1}\Sigma_{11}A \\
   \rho(x,v)&=D_1^{-1}\Sigma_{12}B \\
   \rho(y,u)&=D_2^{-1}\Sigma_{21}A \\
   \rho(y,v)&=D_2^{-1}\Sigma_{22}B \\
   \end{align}
   $$
   其中$D_1=\text{diag}(\sqrt{V(x_1)},...,\sqrt{V(x_p)}),D_2=\text{diag}(\sqrt{V(y_1)},...,\sqrt{V(y_q)})$。

   更进一步，还可以证明原始变量与典型变量之间的复相关系数是
   $$
   \begin{align}
   \rho_{u_i\cdot y}=\rho_i=\sqrt{\lambda_i} \\
   \rho_{v_i\cdot x}=\rho_i=\sqrt{\lambda_i} 
   \end{align}
   $$

1. （普通相关、复相关、典型相关性的关系）复相关是$x$的维数$p=1$或者$y$的维数$q=1$时，典型相关的特例；简单相关是典型相关在$p=q=1$下的特例，因而也是复相关的特例。

1. （标准化改进）为了消除单位差异带来的影响，我们希望用标准化后的$x^*,y^*$来代替原本数据$x,y$来计算。这只需要将之前算式中的协方差矩阵$\Sigma_{ij}(i=1,2,j=1,2)$换成相关系数矩阵$R_{ij}(i=1,2,j=1,2)$即可。由于有关系$R_{ii}=D_{i}^{-1}\Sigma_{ii}D_{i}^{-1}(i=1,2)$，所以可以推出$ R_{11}^{-1} R_{12} R_{22}^{-1} R_{21}=D_1\Sigma_{11}^{-1} \Sigma_{12} \Sigma_{22}^{-1} \Sigma_{21}D_1^{-1}$，也即二者相似。这意味着，使用$x,y$得到的$E$和使用$x^*,y^*$得到的$E^*$相似，二者特征值相同，因而典型相关性系数$\rho$也相同，而特征向量也即典型变量之间会相差一个用于相似的变换，也即$a_i^*=D_1a_i$。同理有$F^*=D_2FD_2^{-1},b_i^*=D_2b_i$。此时，典型变量会变为
   $$
   u_i^*={a_i^*}'x^*=a_i'D_1D_1^{-1}(x-\mu_x)=u_i-a_i'\mu_x \\
   v_i^*={b_i^*}'y^*=b_i'D_2D_2^{-1}(y-\mu_y)=v_i-b_i'\mu_y \\
   $$
   可以看作是原本的典型变量进行了中心化。

# 白噪声检验

### LB检验/Box检验

对于一个序列，如果是白噪声，那么数据之间不会存在相关性。LB检验基于一系列滞后阶数，判断序列总体的相关性或者说随机性是否存在。

它的原假设是$H_0:\hat\rho_1=\hat\rho_2=\cdots=\hat\rho_h=0$，也即序列是白噪声。所用的统计量是$Q=n(n+2)\sum\limits_{k=1}^h\displaystyle\frac{\hat\rho_k}{n-k}$，在原假设下该统计量服从自由度为$h$的卡方分布。当p值小的时候拒绝原假设，认为不是白噪声。

在R语言中，使用`Box.test (x, lag = 10, type = "Ljung")`来实现。其中lag指定的滞后的期数，type指定统计量是否经过修正。