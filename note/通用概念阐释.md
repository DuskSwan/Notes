[toc]



# 一、宏观概念

## 统计学（一元与多元）

一元统计分析可以认为是研究一个随机变量的统计规律的学科，多元统计分析则是在研究多个随机变量之间相互依赖关系。大体上讲，是收集数据，提取数据中的信息，对所研究的问题作出推断。

Kendall在《多元统计》一书中，把多元统计研究的内容归为以下几类：降维问题、分类问题、变量间相互依赖关系、多元分布统计推断（参数估计与假设检验）、分布的理论基础。

又可分为参数统计与非参数统计。参数统计依赖“模型”，先假定数据服从某个模型，然后估计这个模型中的参数，或者对模型的有效性作出检验，因此统计学可以成为“建模”的手段。非参数统计不对数据满足的模型做出假设，只考虑对数据做出某些推断。

## 数据科学

研究数据的科学。研究手段既涵盖了统计的方法（推断、检验），又涵盖了机器的方法（设计算法），当然还有一些别的（比如具体领域内的专业知识）。可以看作是统计与机器学习的应用。

## 人工智能

人工智能 (Artificial Intelligence, AI) 可以被定义成一个像人类一样理性思考与行动的系统。不过，现在的人工智能范围极其广阔，能够完成特定的任务的机器系统，似乎都可以被冠以人工智能的名字。

机器学习是人工智能领域的一部分。人工智能可以用来做数据分析。事实上，我感觉现在用计算机做啥都叫个人工智能……这个词都被用烂了，它是涵盖范围最广泛的概念，具体关系应该是人工智能$\supset$机器学习$\supset$深度学习$\approx$神经网络。

## 机器学习

机器学习本质上是在构筑一个固定的“算法”，这个算法可以针对一些数据算出一些结论。具体来说，机器学习所做的事情是让机器从数据中确定一些参数，进而确定算法，进而处理新的数据。这样的算法可以来自一个统计学中的模型，也可以来自纯粹穷举，或者是什么其他思路。至于机器学习与统计的关系，应该说有所交集，但不相同。

从不同的角度看，机器学习方法有多种分类。可以分为参数方法和非参数方法；有监督方法和无监督方法；传统机器学习与深度学习，等等。

## 深度学习/神经网络

深度学习是一类以神经网络为架构，对资料进行表征学习的方法，因为神经网络有“层”的概念，越多层数（越深）的网络通常能力越强，所以称为深度学习。

# 二、对数据的描述

数据通常会以表格的形式给出：

| 编号  | 属性x1   | 属性x2   | ...  | 属性xp   | 目标y |
| ----- | -------- | -------- | ---- | -------- | ----- |
| 个体1 | $x_{11}$ | $x_{12}$ | ...  | $x_{1p}$ | $y_1$ |
| 个体2 | $x_{21}$ | $x_{22}$ | ...  | $x_{2p}$ | $y_2$ |
| ...   | ...      | ...      | ...  | ...      | ...   |
| 个体n | $x_{n1}$ | $x_{n2}$ | ...  | $x_{np}$ | $y_n$ |

定义以下概念

- 数据集：记录数据的表格。通常每行记录一个个体的信息，每列记录不同个体的同属性数据。不包含目标列的数据可以用矩阵$X=(x_{ij})$记。

- 样本：数据集的一行是一个样本。可以用$x^{(i)}$来表示第$i$个样本（行向量）。

- 特征：数据集的每一列是一个特征。通常将其中一项认为是受其他特征影响的因变量，其他的是自变量。有时，仅仅把自变量列看作特征。用$x_i$来表示第$i$个特征（列向量）。

- 标签：作为预测目标的特征是标签，或者叫目标数组、因变量，可以用$y=(y_1,\cdots,y_n)'$记。

- 模型：自变量与因变量的关系即模型，模型本质上是函数，但未必能写出表达式。在上例中是$f$。

- 超参数：在选择模型类时就要确定的参数，比如是否中心化等。在上例中是$\theta$。这些参数由于各种原因，不适合根据数据来确定，需要人为指定。

- 参数：模型中待定的变量，需要根据数据求出一些值作为参数，使得模型的预测效果最好。在上例中是$\beta$。在确定$\beta$之前，模型其实是模型空间中的众多函数，确定了$\beta$之后，模型才是一个确定可用的函数。二者容易混淆，要根据语境判断。

# 三、模型建立的过程

损失：

训练集：

验证集：

测试集：



# 二、分析过程

数据分析的大致过程是数据预处理→选择模型→训练模型→评价模型，如果模型比较好就可以使用，否则重新选择模型。有时我们对数据服从的模型没有头绪，可以先进行数据感知，查看数据的分布特点，再做进一步打算。

数据预处理，指的是讲原始数据处理成便于后续操作的过程。其中有的是为了让后续操作具有可能性，比如缺失值处理、特征降维、离散特征连续化等；有的则是为了让模型具有更好的效果，比如去噪、归一化等。

数据感知，即用各种指标反应数据的特点。通常包括画散点图查看样本分布、计算协方差矩阵、计算特征与标签的相关来反应特征重要程度等等。

选择模型顾名思义，就是选择合适的模型类型，并确定超参数。

训练模型，指的是根据已知的数据，求出模型的参数使得模型达到最有效果。这本质上是个最优化问题，可以使用多种算法来解。比如使用梯度下降法，就是每读取一个（或一些）样本，便可以计算一次损失，用损失对参数的导数更新参数，如此用掉所有样本，就得到了最终的参数。

评价模型，也可称为模型诊断，指将一些数据带入求解出的模型算出一些指标，用指标衡量这个模型的好坏。这一步通常和训练模型结合进行，先将数据划分为训练集与测试集两部分，用训练集的数据求解参数，再用测试集的数据带入模型计算评价指标。还有交叉验证等更加复杂的方案。

在训练神经网络时，情况要复杂一些。由于训练神经网络需要的数据量非常大，通常要将全部数据分为很多小部分，每一部分称为一个batch，每次只向神经网络中输入一个batch，这才能够运行。如果全部的数据还不够多，就将这些数据重复使用，每一次使用全部数据称为一个epoch。实际上模型运行的次数是epoch_n * batch_n 这么多次，每次计算了batch_size条样本。

