**参考**

主要内容：https://zhuanlan.zhihu.com/p/311698431

**目录**

[toc]





# GAN

## 简介

GANs（生成对抗网络，Generative Adversarial Networks）是由Ian Goodfellow等人在2014年提出的一种深度学习模型。GANs的主要出发点是机器学习中生成模型的问题，即给定一些无标签的真实数据，可以得到一个生成模型，该模型生成的数据和真实数据分布一致。

常见的应用包括

- 图像生成：如超分辨率、图像修复等。

- 数据增强：通过生成新的数据样本来扩展数据集。

- 领域迁移：如风格转换、图像到图像的转换等。



## 思路

GANs由两个主要部分组成：生成器（Generator）和判别器（Discriminator）。

1. **生成器（Generator）**：它的任务是从随机噪声中生成逼真的数据，目的是欺骗判别器，使其认为生成的数据是真实的。生成器通过不断学习，生成的数据会越来越接近真实数据的分布。
2. **判别器（Discriminator）**：判别器的任务是区分真实数据和生成器生成的数据。它通过判断输入的数据是否为真实数据来进行优化。它的目标是尽可能正确地分类输入数据是真实的还是生成的。

GANs通过对抗的方式进行训练，生成器和判别器相互竞争。生成器的目标是生成能欺骗判别器的假数据，而判别器的目标是尽量正确地区分真实数据和生成数据。随着训练的进行，生成器会越来越擅长生成逼真的数据，而判别器也会不断提升其区分能力。最终，生成器生成的数据将与真实数据难以区分。

假设我们有两个网络，生成器G和判别器D。G是一个生成图片的网络，它接收一个随机的噪声（图像）z，通过这个噪声生成图片，记做G(z)；D是一个判别网络，判别一张图片是不是“真实的”。它的输入参数是x，x代表一张图片，输出D(x)代表x为真实图片的概率。

在训练过程中，生成网络G的目标就是尽量生成真实的图片去欺骗判别网络D。而D的目标就是尽量把G生成的图片和真实的图片分别开来。这样，G和D构成了一个动态的“博弈过程”。

最后博弈的结果是什么？在最理想的状态下，G可以生成足以“以假乱真”的图片G(z)。对于D来说，它难以判定G生成的图片究竟是不是真实的，因此D(G(z)) = 0.5。这样我们的目的就达成了：我们得到了一个生成式的模型G，它可以用来生成图片。

下面用数学语言描述这一优化目标：

假设目标图像x的分布为q(x)，噪声z的分布为p(z)，判别器本身要判别准确（真实的图片和生成的图片二者都要能判别），因此判别器目标是
$$
\max_D E_{x\sim q(x)}[\log D(x)]+E_{z\sim p(z)}[\log (1-D(G(z))]
$$
> 关于这里为什么要用对数函数，可以解释为该形式来自交叉熵，因此具有交叉熵的优势。不过实际上也可以换成别的，比如将log函数换成平方函数，Least Squares GAN（LSGAN）就是这么做的，用最小化平方误差代替最大化交叉熵，取得了更稳定的训练效果。

生成器要误导判别器的判断，相当于生成器的目的是让当前的判别器错判，因此总体目标是
$$
\min_G \max_D E_{x\sim q(x)}[\log D(x)] + E_{z\sim p(z)}[\log (1-D(G(z)))]
$$
对于如果生成器固定，那么判别器的优化目标就是
$$
\min_G E_{z\sim p(z)}[\log (1-D(G(z)))]=\max_G E_{z\sim p(z)}[\log D(G(z))]
$$
这也可以理解为是，是要尽可能地让生成出来的”假“样本被判为真实（让$D(G(z))$尽可能高）。

> 值得注意的是，总体目标是一个$\min\max$函数，理想情况下，最优解应该是一个鞍点。所以训练时也要分开训练，每一步先训练D（找D的最优解）再训练G（找G的最优解）。如果同时更新G和D，是不会收敛到鞍点的。

更新时，判别器和生成器依次更新，更新其中一个的时候固定另一个，训练的伪代码如下

---

训练的每一轮迭代包括训练判别器和训练生成器，共迭代T轮：

更新判别器，每轮k步：

- 取m个噪声$z_1,...,z_m$，和m个真实样本$x_1,...,x_m$
- 以$\nabla_{\theta_D} \frac1m \sum_{i=1}^m[\log D(x_i)+\log(1-D(G(z_i)))]$为梯度，**加上**梯度来更新参数
  （最大化目标=增加函数值=梯度上升方向=加梯度值）

更新判别器，每轮1步：

- 取m个噪声$z_1,...,z_m$
- 以$\nabla_{\theta_G} \frac1m \sum_{i=1}^m \log(1-D(G(z_i)))$​为梯度，**减去**梯度来更新参数
  （最小化目标=减少函数值=梯度下降方向=减梯度值）

---





# CycleGAN

## 简介

CycleGAN（循环生成对抗网络）是GAN的一个变种，主要用于图像到图像的转换任务。它的关键思想是实现**无监督的图像到图像的转换**，即不需要成对的图像数据进行训练。典型的应用场景包括风格迁移（将实景照片转为油画）、图像修复（模糊图片变清晰）等。

## 思路

以风格转换为例，我们的目的是将一种画风（分布）下的图像转换到另一种画风（分布）下，并在此过程中保证图像的内容（信息）不变。使用的数据集是两种画风下的多个图像，但它们并不具有一一对应关系（因而不能直接训练一个端到端的网络）。

如果只是为了转变分布，那么采用原始的GAN即可，然而还需要解决“画面信息一致性”的问题。CycleGAN采用了一种类似自编码器的思想，如果一个图像X被函数G转变了分布，又被另一个函数F变回原始分布，而X=F(G(X))也即转变前后非常接近，那就能说明在此过程中一些“信息”得到了保留。

将图片的原始分布记为源域$X$，目标分布记为目标域$Y$，既然我们希望能在两个领域之间做迁移，自然需要两个方向的生成器和两个领域的判别器。定义

- 正向生成器$G:X \to Y$
- 反向生成器$F:Y \to X$
- 目标域判别器$D_Y$
- 源域判别器$D_X$

这里涉及到两种类型的损失函数，一种是对抗损失（Adversarial Loss），和GAN相同，描述转换分布时生成器和判别器的损失；另一种是循环一致性损失（Cycle Consistency Loss），描述来回转换后的图像相似性，确保不丢失内容信息。损失函数的定义如下
$$
L_{GAN}(G,D_Y,X,Y) = E_{y\sim p_{data}(y)}[\log D_Y(y)] + E_{x\sim p_{data}(x)}[\log (1-D_Y(G(x)))] \\
L_{GAN}(F,D_X,Y,X) = E_{x\sim p_{data}(x)}[\log D_X(x)] + E_{y\sim p_{data}(y)}[\log (1-D_X(F(y)))] \\
L_{cyc}(G,F) = E_{x\sim p_{data}(x)}[\|F(G(x))-x\|_1] + E_{y\sim p_{data}(y)}[\|G(F(y))-y\|_1] \\
L_{total}(G,F,D_X,D_Y) = L_{GAN}(G,D_Y,X,Y) + L_{GAN}(F,D_X,Y,X) + L_{cyc}(G,F)
$$
我们希望生成器能骗过判别器，所以优化目标为
$$
\min_{G,F} \max_{D_X,D_Y} L_{total}(G,F,D_X,D_Y)
$$
虽然定义了总的损失函数，但训练的时候和GAN一样，生成器和判别器是依次固定的。

训练过程的伪代码如下

---

训练的每一轮迭代包括训练判别器和训练生成器，共迭代 T 轮：

1. 更新判别器，每轮 k 步：
   - 取 $m$ 个实景图像样本 $x_1, \dots, x_m$ 和 $m$ 个油画风格图像样本 $y_1, \dots, y_m$
   - 生成伪实景图像 $F(y_1), \dots, F(y_m)$ 和伪油画风格图像 $G(x_1), \dots, G(x_m)$
   - 对于判别器 $D_X$：
     - 以 $\nabla_{\theta_{D_X}} \frac{1}{m} \sum_{i=1}^m [\log D_X(x_i) + \log(1 - D_X(F(y_i)))]$ 为梯度，**加上**梯度来更新参数（最大化区分真实图像和生成图像的能力）。
   - 对于判别器$D_Y$：
     - 以 $\nabla_{\theta_{D_Y}} \frac{1}{m} \sum_{i=1}^m [\log D_Y(y_i) + \log(1 - D_Y(G(x_i)))]$ 为梯度，**加上**梯度来更新参数（最大化区分真实图像和生成图像的能力）。
2. 更新生成器，每轮 1 步：
   - 取 $m$ 个实景图像样本 $x_1, \dots, x_m$，和 $m$ 个油画风格图像样本 $y_1, \dots, y_m$
   - 对于生成器 $G$（将实景图像转换为油画风格）：
     - 以 $\nabla_{\theta_G} \frac{1}{m} \sum_{i=1}^m [\log(1 - D_Y(G(x_i))) + \lambda \| F(G(x_i)) - x_i \|]$ 为梯度，**减去**梯度来更新参数（对抗损失+循环一致性损失，确保风格转换的同时保持图像内容一致）。
   - 对于生成器 $F$（将油画风格图像转换为实景）：
     - 以 $\nabla_{\theta_F} \frac{1}{m} \sum_{i=1}^m [\log(1 - D_X(F(y_i))) + \lambda \| G(F(y_i)) - y_i \|]$ 为梯度，**减去**梯度来更新参数（对抗损失+循环一致性损失，确保风格转换的同时保持图像内容一致）。

---



## 训练细节

为了提高训练的稳定性，论文采用了Least Squares GAN（LSGAN）替代标准的对抗损失。这种方法通过最小化平方误差而不是最大化交叉熵，使得训练更加稳定，并生成质量更高的图像。

为了减少模型训练中的震荡现象，判别器更新时并不使用最新生成的图像，而是使用从之前生成的图像中采样的历史图像，历史缓冲区存储了最近生成的50张图像。

关于后者，详细解释一下。在标准的GAN训练中，生成器和判别器是同步更新的，然而，训练过程中有时会出现生成器更新得太快，从而可能导致判别器过拟合到生成器的某些模式，而生成器在之后的更新中跳出当前状态，导致训练周期性震荡。历史缓冲区（Historical Buffer）通过延迟引入生成的假样本来打破这种不平衡，具体来说，CycleGAN的历史缓冲区中存储了最近生成的50张图像。当生成器生成新的假样本时，系统会随机从缓冲区中选择旧的生成图像代替最新生成的图像来更新判别器。这意味着，生成器并不会始终面对完全更新的判别器，能够使得训练过程更平滑。
