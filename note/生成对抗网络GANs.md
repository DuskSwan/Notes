#### 参考

主要内容：https://zhuanlan.zhihu.com/p/311698431

# 简介

GANs（生成对抗网络，Generative Adversarial Networks）是由Ian Goodfellow等人在2014年提出的一种深度学习模型。GANs的主要出发点是机器学习中生成模型的问题，即给定一些无标签的真实数据，可以得到一个生成模型，该模型生成的数据和真实数据分布一致。

常见的应用包括

- 图像生成：如超分辨率、图像修复等。

- 数据增强：通过生成新的数据样本来扩展数据集。

- 领域迁移：如风格转换、图像到图像的转换等。



# 思路

GANs由两个主要部分组成：生成器（Generator）和判别器（Discriminator）。

1. **生成器（Generator）**：它的任务是从随机噪声中生成逼真的数据，目的是欺骗判别器，使其认为生成的数据是真实的。生成器通过不断学习，生成的数据会越来越接近真实数据的分布。
2. **判别器（Discriminator）**：判别器的任务是区分真实数据和生成器生成的数据。它通过判断输入的数据是否为真实数据来进行优化。它的目标是尽可能正确地分类输入数据是真实的还是生成的。

GANs通过对抗的方式进行训练，生成器和判别器相互竞争。生成器的目标是生成能欺骗判别器的假数据，而判别器的目标是尽量正确地区分真实数据和生成数据。随着训练的进行，生成器会越来越擅长生成逼真的数据，而判别器也会不断提升其区分能力。最终，生成器生成的数据将与真实数据难以区分。

假设我们有两个网络，生成器G和判别器D。G是一个生成图片的网络，它接收一个随机的噪声（图像）z，通过这个噪声生成图片，记做G(z)；D是一个判别网络，判别一张图片是不是“真实的”。它的输入参数是x，x代表一张图片，输出D(x)代表x为真实图片的概率。

在训练过程中，生成网络G的目标就是尽量生成真实的图片去欺骗判别网络D。而D的目标就是尽量把G生成的图片和真实的图片分别开来。这样，G和D构成了一个动态的“博弈过程”。

最后博弈的结果是什么？在最理想的状态下，G可以生成足以“以假乱真”的图片G(z)。对于D来说，它难以判定G生成的图片究竟是不是真实的，因此D(G(z)) = 0.5。这样我们的目的就达成了：我们得到了一个生成式的模型G，它可以用来生成图片。

下面用数学语言描述这一优化目标：

假设目标图像x的分布为q(x)，噪声z的分布为p(z)，判别器本身要判别准确（真实的图片和生成的图片二者都要能判别），因此判别器目标是
$$
\max_D E_{x\sim q(x)}[\log D(x)]+E_{z\sim p(z)}[\log (1-D(G(z))]
$$
生成器要误导判别器的判断，相当于生成器的目的是让当前的判别器错判，因此总体目标是
$$
\min_G \max_D E_{x\sim q(x)}[\log D(x)] + E_{z\sim p(z)}[\log (1-D(G(z)))]
$$
对于如果生成器固定，那么判别器的优化目标就是
$$
\max_G E_{z\sim p(z)}[\log (1-D(G(z)))]=\min_G E_{z\sim p(z)}[\log D(G(z))]
$$
更新时，判别器和生成器依次更新，更新其中一个的时候固定另一个，训练的伪代码如下

---

训练的每一轮迭代包括训练判别器和训练生成器，共迭代T轮

更新判别器，每轮k步：

- 取m个噪声$z_1,...,z_m$，和m个真实样本$x_1,...,x_m$
- 以$\nabla_{\theta_D} \frac1m \sum_{i=1}^m[\log D(x_i)+\log(1-D(G(z_i)))]$为梯度，**加上**梯度来更新参数
  （最大化目标=增加函数值=梯度上升方向=加梯度值）

更新判别器，每轮1步：

- 取m个噪声$z_1,...,z_m$
- 以$\nabla_{\theta_G} \frac1m \sum_{i=1}^m \log(1-D(G(z_i)))$​为梯度，**减去**梯度来更新参数
  （最小化目标=减少函数值=梯度下降方向=减梯度值）

---

